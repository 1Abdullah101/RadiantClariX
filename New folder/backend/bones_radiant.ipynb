{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fd6bd50-8430-4bbf-8547-a8e1f48b4a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bones_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bones_api.py\n",
    "# bones_api.py\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io, base64\n",
    "\n",
    "app = FastAPI(title=\"Bone Fracture Detection API\")\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ---- Load Model ----\n",
    "def load_model():\n",
    "    num_classes = 7\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(\"model.pt\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# ---- Class Names (same as your training dataset) ----\n",
    "CLASS_NAMES = [\n",
    "    'elbow positive',\n",
    "    'fingers positive',\n",
    "    'forearm fracture',\n",
    "    'humerus fracture',\n",
    "    'humerus',\n",
    "    'shoulder fracture',\n",
    "    'wrist positive'\n",
    "]\n",
    "\n",
    "# ---- Assign colors per class ----\n",
    "CLASS_COLORS = {\n",
    "    'elbow positive': \"red\",\n",
    "    'fingers positive': \"orange\",\n",
    "    'forearm fracture': \"green\",\n",
    "    'humerus fracture': \"blue\",\n",
    "    'humerus': \"purple\",\n",
    "    'shoulder fracture': \"yellow\",\n",
    "    'wrist positive': \"cyan\"\n",
    "}\n",
    "\n",
    "# ---- Prediction Endpoint ----\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        contents = await file.read()\n",
    "        image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        img_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "\n",
    "        boxes = outputs[0]['boxes']\n",
    "        scores = outputs[0]['scores']\n",
    "        labels = outputs[0]['labels']\n",
    "\n",
    "        threshold = 0.5\n",
    "        filtered_boxes = boxes[scores > threshold]\n",
    "        filtered_scores = scores[scores > threshold]\n",
    "        filtered_labels = labels[scores > threshold]\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        FONT_SIZE = 30\n",
    "        font = ImageFont.load_default(FONT_SIZE)\n",
    "        \n",
    "\n",
    "        for i, box in enumerate(filtered_boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            label_idx = int(filtered_labels[i].item())\n",
    "            label_name = CLASS_NAMES[label_idx] if label_idx < len(CLASS_NAMES) else f\"cls_{label_idx}\"\n",
    "            color = CLASS_COLORS.get(label_name, \"red\")\n",
    "            score = filtered_scores[i].item()\n",
    "\n",
    "            # Draw bounding box\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=3)\n",
    "            draw.text((x1 + 5, y1 + 5), f\"{label_name}: {score:.2f}\", fill=color, font=font)\n",
    "\n",
    "        # Convert image to base64 for React Native\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        return {\n",
    "            \"detections\": len(filtered_boxes),\n",
    "            \"image_base64\": img_str\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\"bones_api:app\", host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa41820-4a2a-46a7-af11-fdce1e8b01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bones.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bones.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "\n",
    "# ---- Setup ----\n",
    "st.title(\"ðŸ©» Bone Fracture Detection (Faster R-CNN)\")\n",
    "st.write(\"Upload an X-ray image to detect fractures using the trained model.\")\n",
    "\n",
    "# ---- Load model ----\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    num_classes = 7  # same as training\n",
    "    classes = ['elbow positive', 'fingers positive', 'forearm fracture', \n",
    "               'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive']\n",
    "    \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"model.pt\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model, classes\n",
    "\n",
    "model, classes = load_model()\n",
    "\n",
    "# ---- File upload ----\n",
    "uploaded_file = st.file_uploader(\"Upload an image (jpg/png)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Save temporarily\n",
    "    tfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "    tfile.write(uploaded_file.read())\n",
    "    \n",
    "    # Read and preprocess\n",
    "    image = Image.open(tfile.name).convert(\"RGB\")\n",
    "    img_np = np.array(image)\n",
    "    img_tensor = torchvision.transforms.functional.to_tensor(img_np).unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        preds = model(img_tensor)\n",
    "\n",
    "    pred = preds[0]\n",
    "    boxes = pred['boxes'].cpu().numpy()\n",
    "    scores = pred['scores'].cpu().numpy()\n",
    "    labels = pred['labels'].cpu().numpy()\n",
    "\n",
    "    threshold = st.slider(\"Confidence threshold\", 0.0, 1.0, 0.5, 0.05)\n",
    "    img_draw = img_np.copy()\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if scores[i] > threshold:\n",
    "            (x1, y1, x2, y2) = box.astype(int)\n",
    "            label = classes[labels[i]]\n",
    "            cv2.rectangle(img_draw, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(img_draw, f\"{label}: {scores[i]:.2f}\", (x1, y1-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
    "\n",
    "    st.image(img_draw, caption=\"Detection Results\", use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d088938-c055-4c5a-932e-dd99716a2a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run bones.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
